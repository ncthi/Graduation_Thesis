{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8b7ba1-b75f-42ab-b4b7-ebd6ac652704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resevit_road import restevit_road_cls,restevit_road_cls_lightweight\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis,flop_count_table\n",
    "from Load_data import Torch_load\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from Report_model.Report_Torch import Class_Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2136daff-e427-48a9-a1bc-49441dfb31b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 32, 112, 112]           4,704\n",
      "       BatchNorm2d-2          [1, 32, 112, 112]              64\n",
      "              ReLU-3          [1, 32, 112, 112]               0\n",
      "         MaxPool2d-4            [1, 32, 56, 56]               0\n",
      "         resnet_in-5            [1, 32, 56, 56]               0\n",
      "            Conv2d-6          [1, 16, 112, 112]             432\n",
      "       BatchNorm2d-7          [1, 16, 112, 112]              32\n",
      "         Hardswish-8          [1, 16, 112, 112]               0\n",
      "         ConvLayer-9          [1, 16, 112, 112]               0\n",
      "           Conv2d-10          [1, 16, 112, 112]             144\n",
      "      BatchNorm2d-11          [1, 16, 112, 112]              32\n",
      "        Hardswish-12          [1, 16, 112, 112]               0\n",
      "        ConvLayer-13          [1, 16, 112, 112]               0\n",
      "           Conv2d-14          [1, 16, 112, 112]             256\n",
      "      BatchNorm2d-15          [1, 16, 112, 112]              32\n",
      "        ConvLayer-16          [1, 16, 112, 112]               0\n",
      "           DSConv-17          [1, 16, 112, 112]               0\n",
      "    IdentityLayer-18          [1, 16, 112, 112]               0\n",
      "    ResidualBlock-19          [1, 16, 112, 112]               0\n",
      "     OpSequential-20          [1, 16, 112, 112]               0\n",
      "       input_stem-21          [1, 16, 112, 112]               0\n",
      "           Conv2d-22            [1, 32, 56, 56]           9,216\n",
      "      BatchNorm2d-23            [1, 32, 56, 56]              64\n",
      "             ReLU-24            [1, 32, 56, 56]               0\n",
      "           Conv2d-25            [1, 32, 56, 56]           9,216\n",
      "      BatchNorm2d-26            [1, 32, 56, 56]              64\n",
      "             ReLU-27            [1, 32, 56, 56]               0\n",
      "       BasicBlock-28            [1, 32, 56, 56]               0\n",
      "     resnet_block-29            [1, 32, 56, 56]               0\n",
      "           Conv2d-30          [1, 64, 112, 112]           1,024\n",
      "      BatchNorm2d-31          [1, 64, 112, 112]             128\n",
      "        Hardswish-32          [1, 64, 112, 112]               0\n",
      "        ConvLayer-33          [1, 64, 112, 112]               0\n",
      "           Conv2d-34            [1, 64, 56, 56]             576\n",
      "      BatchNorm2d-35            [1, 64, 56, 56]             128\n",
      "        Hardswish-36            [1, 64, 56, 56]               0\n",
      "        ConvLayer-37            [1, 64, 56, 56]               0\n",
      "           Conv2d-38            [1, 32, 56, 56]           2,048\n",
      "      BatchNorm2d-39            [1, 32, 56, 56]              64\n",
      "        ConvLayer-40            [1, 32, 56, 56]               0\n",
      "           MBConv-41            [1, 32, 56, 56]               0\n",
      "    ResidualBlock-42            [1, 32, 56, 56]               0\n",
      "           Conv2d-43           [1, 128, 56, 56]           4,096\n",
      "      BatchNorm2d-44           [1, 128, 56, 56]             256\n",
      "        Hardswish-45           [1, 128, 56, 56]               0\n",
      "        ConvLayer-46           [1, 128, 56, 56]               0\n",
      "           Conv2d-47           [1, 128, 56, 56]           1,152\n",
      "      BatchNorm2d-48           [1, 128, 56, 56]             256\n",
      "        Hardswish-49           [1, 128, 56, 56]               0\n",
      "        ConvLayer-50           [1, 128, 56, 56]               0\n",
      "           Conv2d-51            [1, 32, 56, 56]           4,096\n",
      "      BatchNorm2d-52            [1, 32, 56, 56]              64\n",
      "        ConvLayer-53            [1, 32, 56, 56]               0\n",
      "           MBConv-54            [1, 32, 56, 56]               0\n",
      "    IdentityLayer-55            [1, 32, 56, 56]               0\n",
      "    ResidualBlock-56            [1, 32, 56, 56]               0\n",
      "     OpSequential-57            [1, 32, 56, 56]               0\n",
      "     MBConv_stage-58            [1, 32, 56, 56]               0\n",
      "           Conv2d-59            [1, 64, 28, 28]          18,432\n",
      "      BatchNorm2d-60            [1, 64, 28, 28]             128\n",
      "             ReLU-61            [1, 64, 28, 28]               0\n",
      "           Conv2d-62            [1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-63            [1, 64, 28, 28]             128\n",
      "           Conv2d-64            [1, 64, 28, 28]           2,048\n",
      "      BatchNorm2d-65            [1, 64, 28, 28]             128\n",
      "             ReLU-66            [1, 64, 28, 28]               0\n",
      "       BasicBlock-67            [1, 64, 28, 28]               0\n",
      "     resnet_block-68            [1, 64, 28, 28]               0\n",
      "           Conv2d-69           [1, 128, 56, 56]           4,096\n",
      "      BatchNorm2d-70           [1, 128, 56, 56]             256\n",
      "        Hardswish-71           [1, 128, 56, 56]               0\n",
      "        ConvLayer-72           [1, 128, 56, 56]               0\n",
      "           Conv2d-73           [1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-74           [1, 128, 28, 28]             256\n",
      "        Hardswish-75           [1, 128, 28, 28]               0\n",
      "        ConvLayer-76           [1, 128, 28, 28]               0\n",
      "           Conv2d-77            [1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-78            [1, 64, 28, 28]             128\n",
      "        ConvLayer-79            [1, 64, 28, 28]               0\n",
      "           MBConv-80            [1, 64, 28, 28]               0\n",
      "    ResidualBlock-81            [1, 64, 28, 28]               0\n",
      "           Conv2d-82           [1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-83           [1, 256, 28, 28]             512\n",
      "        Hardswish-84           [1, 256, 28, 28]               0\n",
      "        ConvLayer-85           [1, 256, 28, 28]               0\n",
      "           Conv2d-86           [1, 256, 28, 28]           2,304\n",
      "      BatchNorm2d-87           [1, 256, 28, 28]             512\n",
      "        Hardswish-88           [1, 256, 28, 28]               0\n",
      "        ConvLayer-89           [1, 256, 28, 28]               0\n",
      "           Conv2d-90            [1, 64, 28, 28]          16,384\n",
      "      BatchNorm2d-91            [1, 64, 28, 28]             128\n",
      "        ConvLayer-92            [1, 64, 28, 28]               0\n",
      "           MBConv-93            [1, 64, 28, 28]               0\n",
      "    IdentityLayer-94            [1, 64, 28, 28]               0\n",
      "    ResidualBlock-95            [1, 64, 28, 28]               0\n",
      "     OpSequential-96            [1, 64, 28, 28]               0\n",
      "     MBConv_stage-97            [1, 64, 28, 28]               0\n",
      "           Conv2d-98           [1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-99           [1, 128, 14, 14]             256\n",
      "            ReLU-100           [1, 128, 14, 14]               0\n",
      "          Conv2d-101           [1, 128, 14, 14]         147,456\n",
      "     BatchNorm2d-102           [1, 128, 14, 14]             256\n",
      "          Conv2d-103           [1, 128, 14, 14]           8,192\n",
      "     BatchNorm2d-104           [1, 128, 14, 14]             256\n",
      "            ReLU-105           [1, 128, 14, 14]               0\n",
      "      BasicBlock-106           [1, 128, 14, 14]               0\n",
      "    resnet_block-107           [1, 128, 14, 14]               0\n",
      "          Conv2d-108           [1, 256, 28, 28]          16,640\n",
      "       Hardswish-109           [1, 256, 28, 28]               0\n",
      "       ConvLayer-110           [1, 256, 28, 28]               0\n",
      "          Conv2d-111           [1, 256, 14, 14]           2,560\n",
      "       Hardswish-112           [1, 256, 14, 14]               0\n",
      "       ConvLayer-113           [1, 256, 14, 14]               0\n",
      "          Conv2d-114           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-115           [1, 128, 14, 14]             256\n",
      "       ConvLayer-116           [1, 128, 14, 14]               0\n",
      "          MBConv-117           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-118           [1, 128, 14, 14]               0\n",
      "          Conv2d-119           [1, 384, 14, 14]          49,152\n",
      "       ConvLayer-120           [1, 384, 14, 14]               0\n",
      "          Conv2d-121           [1, 384, 14, 14]           9,600\n",
      "          Conv2d-122           [1, 384, 14, 14]           6,144\n",
      "            ReLU-123           [1, 16, 16, 196]               0\n",
      "            ReLU-124           [1, 16, 16, 196]               0\n",
      "          Conv2d-125           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-126           [1, 128, 14, 14]             256\n",
      "       ConvLayer-127           [1, 128, 14, 14]               0\n",
      "         LiteMLA-128           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-129           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-130           [1, 128, 14, 14]               0\n",
      "          Conv2d-131           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-132           [1, 512, 14, 14]               0\n",
      "       ConvLayer-133           [1, 512, 14, 14]               0\n",
      "          Conv2d-134           [1, 512, 14, 14]           5,120\n",
      "       Hardswish-135           [1, 512, 14, 14]               0\n",
      "       ConvLayer-136           [1, 512, 14, 14]               0\n",
      "          Conv2d-137           [1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-138           [1, 128, 14, 14]             256\n",
      "       ConvLayer-139           [1, 128, 14, 14]               0\n",
      "          MBConv-140           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-141           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-142           [1, 128, 14, 14]               0\n",
      "EfficientViTBlock-143           [1, 128, 14, 14]               0\n",
      "          Conv2d-144           [1, 384, 14, 14]          49,152\n",
      "       ConvLayer-145           [1, 384, 14, 14]               0\n",
      "          Conv2d-146           [1, 384, 14, 14]           9,600\n",
      "          Conv2d-147           [1, 384, 14, 14]           6,144\n",
      "            ReLU-148           [1, 16, 16, 196]               0\n",
      "            ReLU-149           [1, 16, 16, 196]               0\n",
      "          Conv2d-150           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-151           [1, 128, 14, 14]             256\n",
      "       ConvLayer-152           [1, 128, 14, 14]               0\n",
      "         LiteMLA-153           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-154           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-155           [1, 128, 14, 14]               0\n",
      "          Conv2d-156           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-157           [1, 512, 14, 14]               0\n",
      "       ConvLayer-158           [1, 512, 14, 14]               0\n",
      "          Conv2d-159           [1, 512, 14, 14]           5,120\n",
      "       Hardswish-160           [1, 512, 14, 14]               0\n",
      "       ConvLayer-161           [1, 512, 14, 14]               0\n",
      "          Conv2d-162           [1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-163           [1, 128, 14, 14]             256\n",
      "       ConvLayer-164           [1, 128, 14, 14]               0\n",
      "          MBConv-165           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-166           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-167           [1, 128, 14, 14]               0\n",
      "EfficientViTBlock-168           [1, 128, 14, 14]               0\n",
      "    OpSequential-169           [1, 128, 14, 14]               0\n",
      "EfficientViT_stage-170           [1, 128, 14, 14]               0\n",
      "InterleavedLayer-171           [1, 256, 14, 14]               0\n",
      "          Conv2d-172            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-173            [1, 48, 14, 14]              96\n",
      "          Conv2d-174             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-175             [1, 8, 14, 14]              16\n",
      "          Conv2d-176            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-177            [1, 48, 14, 14]              96\n",
      "          Conv2d-178             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-179             [1, 8, 14, 14]              16\n",
      "          Conv2d-180            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-181            [1, 48, 14, 14]              96\n",
      "          Conv2d-182             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-183             [1, 8, 14, 14]              16\n",
      "          Conv2d-184            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-185            [1, 48, 14, 14]              96\n",
      "          Conv2d-186             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-187             [1, 8, 14, 14]              16\n",
      "          Conv2d-188            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-189            [1, 48, 14, 14]              96\n",
      "          Conv2d-190             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-191             [1, 8, 14, 14]              16\n",
      "          Conv2d-192            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-193            [1, 48, 14, 14]              96\n",
      "          Conv2d-194             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-195             [1, 8, 14, 14]              16\n",
      "          Conv2d-196            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-197            [1, 48, 14, 14]              96\n",
      "          Conv2d-198             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-199             [1, 8, 14, 14]              16\n",
      "          Conv2d-200            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-201            [1, 48, 14, 14]              96\n",
      "          Conv2d-202             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-203             [1, 8, 14, 14]              16\n",
      "            ReLU-204           [1, 256, 14, 14]               0\n",
      "          Conv2d-205           [1, 256, 14, 14]          65,536\n",
      "     BatchNorm2d-206           [1, 256, 14, 14]             512\n",
      "CascadedGroupAttention-207           [1, 256, 14, 14]               0\n",
      "          Conv2d-208           [1, 128, 14, 14]          32,896\n",
      "            ReLU-209           [1, 128, 14, 14]               0\n",
      "     BatchNorm2d-210           [1, 128, 14, 14]             256\n",
      "Interaction_block-211           [1, 128, 14, 14]               0\n",
      "InterleavedLayer-212           [1, 256, 14, 14]               0\n",
      "          Conv2d-213            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-214            [1, 48, 14, 14]              96\n",
      "          Conv2d-215             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-216             [1, 8, 14, 14]              16\n",
      "          Conv2d-217            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-218            [1, 48, 14, 14]              96\n",
      "          Conv2d-219             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-220             [1, 8, 14, 14]              16\n",
      "          Conv2d-221            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-222            [1, 48, 14, 14]              96\n",
      "          Conv2d-223             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-224             [1, 8, 14, 14]              16\n",
      "          Conv2d-225            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-226            [1, 48, 14, 14]              96\n",
      "          Conv2d-227             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-228             [1, 8, 14, 14]              16\n",
      "          Conv2d-229            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-230            [1, 48, 14, 14]              96\n",
      "          Conv2d-231             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-232             [1, 8, 14, 14]              16\n",
      "          Conv2d-233            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-234            [1, 48, 14, 14]              96\n",
      "          Conv2d-235             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-236             [1, 8, 14, 14]              16\n",
      "          Conv2d-237            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-238            [1, 48, 14, 14]              96\n",
      "          Conv2d-239             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-240             [1, 8, 14, 14]              16\n",
      "          Conv2d-241            [1, 48, 14, 14]           1,536\n",
      "     BatchNorm2d-242            [1, 48, 14, 14]              96\n",
      "          Conv2d-243             [1, 8, 14, 14]             200\n",
      "     BatchNorm2d-244             [1, 8, 14, 14]              16\n",
      "            ReLU-245           [1, 256, 14, 14]               0\n",
      "          Conv2d-246           [1, 256, 14, 14]          65,536\n",
      "     BatchNorm2d-247           [1, 256, 14, 14]             512\n",
      "CascadedGroupAttention-248           [1, 256, 14, 14]               0\n",
      "          Conv2d-249           [1, 128, 14, 14]          32,896\n",
      "            ReLU-250           [1, 128, 14, 14]               0\n",
      "     BatchNorm2d-251           [1, 128, 14, 14]             256\n",
      "Interaction_block-252           [1, 128, 14, 14]               0\n",
      "          Conv2d-253             [1, 256, 7, 7]         294,912\n",
      "     BatchNorm2d-254             [1, 256, 7, 7]             512\n",
      "            ReLU-255             [1, 256, 7, 7]               0\n",
      "          Conv2d-256             [1, 256, 7, 7]         589,824\n",
      "     BatchNorm2d-257             [1, 256, 7, 7]             512\n",
      "          Conv2d-258             [1, 256, 7, 7]          32,768\n",
      "     BatchNorm2d-259             [1, 256, 7, 7]             512\n",
      "            ReLU-260             [1, 256, 7, 7]               0\n",
      "      BasicBlock-261             [1, 256, 7, 7]               0\n",
      "    resnet_block-262             [1, 256, 7, 7]               0\n",
      "          Conv2d-263           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-264           [1, 512, 14, 14]               0\n",
      "       ConvLayer-265           [1, 512, 14, 14]               0\n",
      "          Conv2d-266             [1, 512, 7, 7]           5,120\n",
      "       Hardswish-267             [1, 512, 7, 7]               0\n",
      "       ConvLayer-268             [1, 512, 7, 7]               0\n",
      "          Conv2d-269             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-270             [1, 256, 7, 7]             512\n",
      "       ConvLayer-271             [1, 256, 7, 7]               0\n",
      "          MBConv-272             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-273             [1, 256, 7, 7]               0\n",
      "          Conv2d-274             [1, 768, 7, 7]         196,608\n",
      "       ConvLayer-275             [1, 768, 7, 7]               0\n",
      "          Conv2d-276             [1, 768, 7, 7]          19,200\n",
      "          Conv2d-277             [1, 768, 7, 7]          12,288\n",
      "            ReLU-278            [1, 32, 16, 49]               0\n",
      "            ReLU-279            [1, 32, 16, 49]               0\n",
      "          Conv2d-280             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-281             [1, 256, 7, 7]             512\n",
      "       ConvLayer-282             [1, 256, 7, 7]               0\n",
      "         LiteMLA-283             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-284             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-285             [1, 256, 7, 7]               0\n",
      "          Conv2d-286            [1, 1024, 7, 7]         263,168\n",
      "       Hardswish-287            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-288            [1, 1024, 7, 7]               0\n",
      "          Conv2d-289            [1, 1024, 7, 7]          10,240\n",
      "       Hardswish-290            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-291            [1, 1024, 7, 7]               0\n",
      "          Conv2d-292             [1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-293             [1, 256, 7, 7]             512\n",
      "       ConvLayer-294             [1, 256, 7, 7]               0\n",
      "          MBConv-295             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-296             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-297             [1, 256, 7, 7]               0\n",
      "EfficientViTBlock-298             [1, 256, 7, 7]               0\n",
      "          Conv2d-299             [1, 768, 7, 7]         196,608\n",
      "       ConvLayer-300             [1, 768, 7, 7]               0\n",
      "          Conv2d-301             [1, 768, 7, 7]          19,200\n",
      "          Conv2d-302             [1, 768, 7, 7]          12,288\n",
      "            ReLU-303            [1, 32, 16, 49]               0\n",
      "            ReLU-304            [1, 32, 16, 49]               0\n",
      "          Conv2d-305             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-306             [1, 256, 7, 7]             512\n",
      "       ConvLayer-307             [1, 256, 7, 7]               0\n",
      "         LiteMLA-308             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-309             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-310             [1, 256, 7, 7]               0\n",
      "          Conv2d-311            [1, 1024, 7, 7]         263,168\n",
      "       Hardswish-312            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-313            [1, 1024, 7, 7]               0\n",
      "          Conv2d-314            [1, 1024, 7, 7]          10,240\n",
      "       Hardswish-315            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-316            [1, 1024, 7, 7]               0\n",
      "          Conv2d-317             [1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-318             [1, 256, 7, 7]             512\n",
      "       ConvLayer-319             [1, 256, 7, 7]               0\n",
      "          MBConv-320             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-321             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-322             [1, 256, 7, 7]               0\n",
      "EfficientViTBlock-323             [1, 256, 7, 7]               0\n",
      "    OpSequential-324             [1, 256, 7, 7]               0\n",
      "EfficientViT_stage-325             [1, 256, 7, 7]               0\n",
      "     ConcatLayer-326             [1, 512, 7, 7]               0\n",
      "          Conv2d-327             [1, 512, 7, 7]           1,024\n",
      "          Conv2d-328             [1, 512, 7, 7]         262,656\n",
      "       LayerNorm-329             [1, 512, 7, 7]          50,176\n",
      "   Combine_block-330             [1, 512, 7, 7]               0\n",
      "restevit_road_backbone-331             [1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-332             [1, 512, 1, 1]               0\n",
      "         Flatten-333                   [1, 512]               0\n",
      "         Dropout-334                   [1, 512]               0\n",
      "            ReLU-335                   [1, 512]               0\n",
      "          Linear-336                     [1, 4]           2,052\n",
      "================================================================\n",
      "Total params: 4,355,460\n",
      "Trainable params: 4,355,460\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 195.92\n",
      "Params size (MB): 16.61\n",
      "Estimated Total Size (MB): 213.11\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add_ encountered 77 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::hardswish encountered 22 time(s)\n",
      "Unsupported operator aten::add encountered 47 time(s)\n",
      "Unsupported operator aten::mul encountered 20 time(s)\n",
      "Unsupported operator aten::pad encountered 4 time(s)\n",
      "Unsupported operator aten::div encountered 4 time(s)\n",
      "Unsupported operator aten::softmax encountered 16 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_mdoel.efficientvit_in.input_stem.op_list.1.shortcut, base_mdoel.stage1.stage.op_list.1.shortcut, base_mdoel.stage2.stage.op_list.1.shortcut, base_mdoel.stage3.stage.op_list.1.context_module.shortcut, base_mdoel.stage3.stage.op_list.1.local_module.shortcut, base_mdoel.stage3.stage.op_list.2.context_module.shortcut, base_mdoel.stage3.stage.op_list.2.local_module.shortcut, base_mdoel.stage4.stage.op_list.1.context_module.shortcut, base_mdoel.stage4.stage.op_list.1.local_module.shortcut, base_mdoel.stage4.stage.op_list.2.context_module.shortcut, base_mdoel.stage4.stage.op_list.2.local_module.shortcut\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'| module                                                  | #parameters or shape   | #flops     |\\n|:--------------------------------------------------------|:-----------------------|:-----------|\\n| model                                                   | 4.359M                 | 0.69G      |\\n|  base_mdoel                                             |  4.357M                |  0.69G     |\\n|   base_mdoel.resnet_in                                  |   4.768K               |   61.014M  |\\n|    base_mdoel.resnet_in.conv                            |    4.704K              |    59.007M |\\n|    base_mdoel.resnet_in.bn                              |    64                  |    2.007M  |\\n|   base_mdoel.efficientvit_in.input_stem.op_list         |   0.928K               |   13.447M  |\\n|    base_mdoel.efficientvit_in.input_stem.op_list.0      |    0.464K              |    6.423M  |\\n|    base_mdoel.efficientvit_in.input_stem.op_list.1.main |    0.464K              |    7.025M  |\\n|   base_mdoel.block1.blocks.0                            |   18.56K               |   58.806M  |\\n|    base_mdoel.block1.blocks.0.conv1                     |    9.216K              |    28.901M |\\n|    base_mdoel.block1.blocks.0.bn1                       |    64                  |    0.502M  |\\n|    base_mdoel.block1.blocks.0.conv2                     |    9.216K              |    28.901M |\\n|    base_mdoel.block1.blocks.0.bn2                       |    64                  |    0.502M  |\\n|   base_mdoel.block2.blocks.0                            |   57.728K              |   45.71M   |\\n|    base_mdoel.block2.blocks.0.downsample                |    2.176K              |    1.857M  |\\n|    base_mdoel.block2.blocks.0.conv1                     |    18.432K             |    14.451M |\\n|    base_mdoel.block2.blocks.0.bn1                       |    0.128K              |    0.251M  |\\n|    base_mdoel.block2.blocks.0.conv2                     |    36.864K             |    28.901M |\\n|    base_mdoel.block2.blocks.0.bn2                       |    0.128K              |    0.251M  |\\n|   base_mdoel.block3.blocks.0                            |   0.23M                |   45.334M  |\\n|    base_mdoel.block3.blocks.0.downsample                |    8.448K              |    1.731M  |\\n|    base_mdoel.block3.blocks.0.conv1                     |    73.728K             |    14.451M |\\n|    base_mdoel.block3.blocks.0.bn1                       |    0.256K              |    0.125M  |\\n|    base_mdoel.block3.blocks.0.conv2                     |    0.147M              |    28.901M |\\n|    base_mdoel.block3.blocks.0.bn2                       |    0.256K              |    0.125M  |\\n|   base_mdoel.block4.blocks.0                            |   0.919M               |   45.146M  |\\n|    base_mdoel.block4.blocks.0.downsample                |    33.28K              |    1.668M  |\\n|    base_mdoel.block4.blocks.0.conv1                     |    0.295M              |    14.451M |\\n|    base_mdoel.block4.blocks.0.bn1                       |    0.512K              |    62.72K  |\\n|    base_mdoel.block4.blocks.0.conv2                     |    0.59M               |    28.901M |\\n|    base_mdoel.block4.blocks.0.bn2                       |    0.512K              |    62.72K  |\\n|   base_mdoel.stage1.stage.op_list                       |   13.888K              |   60.412M  |\\n|    base_mdoel.stage1.stage.op_list.0.main               |    3.968K              |    26.593M |\\n|    base_mdoel.stage1.stage.op_list.1.main               |    9.92K               |    33.819M |\\n|   base_mdoel.stage2.stage.op_list                       |   50.304K              |   52.685M  |\\n|    base_mdoel.stage2.stage.op_list.0.main               |    14.08K              |    22.93M  |\\n|    base_mdoel.stage2.stage.op_list.1.main               |    36.224K             |    29.754M |\\n|   base_mdoel.stage3.stage.op_list                       |   0.522M               |   0.115G   |\\n|    base_mdoel.stage3.stage.op_list.0.main               |    52.224K             |    19.845M |\\n|    base_mdoel.stage3.stage.op_list.1                    |    0.235M              |    47.692M |\\n|    base_mdoel.stage3.stage.op_list.2                    |    0.235M              |    47.692M |\\n|   base_mdoel.stage4.stage.op_list                       |   1.994M               |   0.109G   |\\n|    base_mdoel.stage4.stage.op_list.0.main               |    0.203M              |    19.556M |\\n|    base_mdoel.stage4.stage.op_list.1                    |    0.896M              |    44.719M |\\n|    base_mdoel.stage4.stage.op_list.2                    |    0.896M              |    44.719M |\\n|   base_mdoel.interaction_to_r                           |   0.116M               |   35.098M  |\\n|    base_mdoel.interaction_to_r.attn                     |    82.4K               |    28.55M  |\\n|    base_mdoel.interaction_to_r.downchannel              |    32.896K             |    6.423M  |\\n|    base_mdoel.interaction_to_r.bn                       |    0.256K              |    0.125M  |\\n|   base_mdoel.interaction_to_v                           |   0.116M               |   35.098M  |\\n|    base_mdoel.interaction_to_v.attn                     |    82.4K               |    28.55M  |\\n|    base_mdoel.interaction_to_v.downchannel              |    32.896K             |    6.423M  |\\n|    base_mdoel.interaction_to_v.bn                       |    0.256K              |    0.125M  |\\n|   base_mdoel.concat_block                               |   0.314M               |   12.996M  |\\n|    base_mdoel.concat_block.dw_conv                      |    1.024K              |    25.088K |\\n|    base_mdoel.concat_block.point_conv                   |    0.263M              |    12.845M |\\n|    base_mdoel.concat_block.nor                          |    50.176K             |    0.125M  |\\n|  classification.3                                       |  2.052K                |  2.048K    |\\n|   classification.3.weight                               |   (4, 512)             |            |\\n|   classification.3.bias                                 |   (4,)                 |            |\\n|  apdative                                               |                        |  25.088K   |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=restevit_road_cls_lightweight(num_class=4)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model= model.to(device)\n",
    "summary(model, (3,224,224), batch_size=1)\n",
    "inputs= torch.rand(1,3, 224,224)\n",
    "inputs=inputs.to(device)\n",
    "flops=FlopCountAnalysis(model,inputs)\n",
    "flops.total()\n",
    "flop_count_table(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe0195-54e6-44f2-a70d-eefc0a68a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "output_log=\"output.txt\"\n",
    "def train(epochs_per_fold=30,batch_size=32,image_size=224):\n",
    "    for fold,(dataloader_dict) in enumerate(Torch_load(image_size=image_size,batch_size=batch_size,task=\"multi\")()):\n",
    "        print(\"Fold:\",fold+1)\n",
    "        criterior= nn.CrossEntropyLoss()\n",
    "        if fold<1: optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "        else: optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "        early_stop_thresh = 5\n",
    "        best_accuracy = -1\n",
    "        best_epoch = -1\n",
    "        stop=False\n",
    "        for epoch in range(epochs_per_fold):\n",
    "            if stop==True: break\n",
    "            with open(output_log, 'a') as f:\n",
    "                print(\"Epoch {}/{}\".format(epoch, epochs_per_fold),file=f)\n",
    "            for phase in [\"Train\", \"Val\"]:\n",
    "                if phase == \"Train\":\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    \n",
    "                epoch_loss = 0.0\n",
    "                epoch_corrects = 0\n",
    "                \n",
    "                for inputs, labels in tqdm(dataloader_dict[phase]):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == \"Train\"):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterior(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        \n",
    "                        if phase == \"Train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                    epoch_loss += loss.item()*inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds==labels.data)\n",
    "                epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "                epoch_accuracy = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "                if phase == \"Val\":\n",
    "                    if epoch_accuracy > best_accuracy:\n",
    "                        best_accuracy = epoch_accuracy\n",
    "                        best_epoch = epoch\n",
    "                        save_checkpoint(model, \"ResEViT_multiclass.pth\")\n",
    "                    elif epoch - best_epoch > early_stop_thresh:\n",
    "                        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "                        stop=True  # terminate the training loo\n",
    "                with open(output_log, 'a') as f:\n",
    "                    print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_accuracy), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016506bb-7542-4d7e-b51f-1971db7bf16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7520d53-ce1b-4d9a-9d8c-4b2962ee523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:04<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       169\n",
      "         1.0     0.9136    0.9367    0.9250        79\n",
      "         2.0     0.9505    0.9320    0.9412       103\n",
      "         3.0     0.9841    0.9841    0.9841        63\n",
      "\n",
      "    accuracy                         0.9686       414\n",
      "   macro avg     0.9621    0.9632    0.9626       414\n",
      "weighted avg     0.9688    0.9686    0.9686       414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('ResEViT_multiclass.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "Test_data=Torch_load(image_size=224,batch_size=8,phase=\"Test\",task=\"multi\")()\n",
    "Class_Report(Test_data[\"Test\"],model,device)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6c150-2c31-4231-af82-c5ba38ea90af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
