{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8b7ba1-b75f-42ab-b4b7-ebd6ac652704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resevit_road import restevit_road_cls\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis,flop_count_table\n",
    "from Load_data import Torch_load\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from Load_data.KTorch import load_test \n",
    "from Report_model.Report_Torch import Class_Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2136daff-e427-48a9-a1bc-49441dfb31b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2          [1, 64, 112, 112]             128\n",
      "              ReLU-3          [1, 64, 112, 112]               0\n",
      "         MaxPool2d-4            [1, 64, 56, 56]               0\n",
      "         resnet_in-5            [1, 64, 56, 56]               0\n",
      "            Conv2d-6          [1, 16, 112, 112]             432\n",
      "       BatchNorm2d-7          [1, 16, 112, 112]              32\n",
      "         Hardswish-8          [1, 16, 112, 112]               0\n",
      "         ConvLayer-9          [1, 16, 112, 112]               0\n",
      "           Conv2d-10          [1, 16, 112, 112]             144\n",
      "      BatchNorm2d-11          [1, 16, 112, 112]              32\n",
      "        Hardswish-12          [1, 16, 112, 112]               0\n",
      "        ConvLayer-13          [1, 16, 112, 112]               0\n",
      "           Conv2d-14          [1, 16, 112, 112]             256\n",
      "      BatchNorm2d-15          [1, 16, 112, 112]              32\n",
      "        ConvLayer-16          [1, 16, 112, 112]               0\n",
      "           DSConv-17          [1, 16, 112, 112]               0\n",
      "    IdentityLayer-18          [1, 16, 112, 112]               0\n",
      "    ResidualBlock-19          [1, 16, 112, 112]               0\n",
      "     OpSequential-20          [1, 16, 112, 112]               0\n",
      "       input_stem-21          [1, 16, 112, 112]               0\n",
      "           Conv2d-22            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23            [1, 64, 56, 56]             128\n",
      "             ReLU-24            [1, 64, 56, 56]               0\n",
      "           Conv2d-25            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-26            [1, 64, 56, 56]             128\n",
      "             ReLU-27            [1, 64, 56, 56]               0\n",
      "       BasicBlock-28            [1, 64, 56, 56]               0\n",
      "           Conv2d-29            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-30            [1, 64, 56, 56]             128\n",
      "             ReLU-31            [1, 64, 56, 56]               0\n",
      "           Conv2d-32            [1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-33            [1, 64, 56, 56]             128\n",
      "             ReLU-34            [1, 64, 56, 56]               0\n",
      "       BasicBlock-35            [1, 64, 56, 56]               0\n",
      "     resnet_block-36            [1, 64, 56, 56]               0\n",
      "           Conv2d-37          [1, 64, 112, 112]           1,024\n",
      "      BatchNorm2d-38          [1, 64, 112, 112]             128\n",
      "        Hardswish-39          [1, 64, 112, 112]               0\n",
      "        ConvLayer-40          [1, 64, 112, 112]               0\n",
      "           Conv2d-41            [1, 64, 56, 56]             576\n",
      "      BatchNorm2d-42            [1, 64, 56, 56]             128\n",
      "        Hardswish-43            [1, 64, 56, 56]               0\n",
      "        ConvLayer-44            [1, 64, 56, 56]               0\n",
      "           Conv2d-45            [1, 32, 56, 56]           2,048\n",
      "      BatchNorm2d-46            [1, 32, 56, 56]              64\n",
      "        ConvLayer-47            [1, 32, 56, 56]               0\n",
      "           MBConv-48            [1, 32, 56, 56]               0\n",
      "    ResidualBlock-49            [1, 32, 56, 56]               0\n",
      "           Conv2d-50           [1, 128, 56, 56]           4,096\n",
      "      BatchNorm2d-51           [1, 128, 56, 56]             256\n",
      "        Hardswish-52           [1, 128, 56, 56]               0\n",
      "        ConvLayer-53           [1, 128, 56, 56]               0\n",
      "           Conv2d-54           [1, 128, 56, 56]           1,152\n",
      "      BatchNorm2d-55           [1, 128, 56, 56]             256\n",
      "        Hardswish-56           [1, 128, 56, 56]               0\n",
      "        ConvLayer-57           [1, 128, 56, 56]               0\n",
      "           Conv2d-58            [1, 32, 56, 56]           4,096\n",
      "      BatchNorm2d-59            [1, 32, 56, 56]              64\n",
      "        ConvLayer-60            [1, 32, 56, 56]               0\n",
      "           MBConv-61            [1, 32, 56, 56]               0\n",
      "    IdentityLayer-62            [1, 32, 56, 56]               0\n",
      "    ResidualBlock-63            [1, 32, 56, 56]               0\n",
      "     OpSequential-64            [1, 32, 56, 56]               0\n",
      "     MBConv_stage-65            [1, 32, 56, 56]               0\n",
      "           Conv2d-66           [1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-67           [1, 128, 28, 28]             256\n",
      "             ReLU-68           [1, 128, 28, 28]               0\n",
      "           Conv2d-69           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-70           [1, 128, 28, 28]             256\n",
      "           Conv2d-71           [1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-72           [1, 128, 28, 28]             256\n",
      "             ReLU-73           [1, 128, 28, 28]               0\n",
      "       BasicBlock-74           [1, 128, 28, 28]               0\n",
      "           Conv2d-75           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-76           [1, 128, 28, 28]             256\n",
      "             ReLU-77           [1, 128, 28, 28]               0\n",
      "           Conv2d-78           [1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-79           [1, 128, 28, 28]             256\n",
      "             ReLU-80           [1, 128, 28, 28]               0\n",
      "       BasicBlock-81           [1, 128, 28, 28]               0\n",
      "     resnet_block-82           [1, 128, 28, 28]               0\n",
      "           Conv2d-83           [1, 128, 56, 56]           4,096\n",
      "      BatchNorm2d-84           [1, 128, 56, 56]             256\n",
      "        Hardswish-85           [1, 128, 56, 56]               0\n",
      "        ConvLayer-86           [1, 128, 56, 56]               0\n",
      "           Conv2d-87           [1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-88           [1, 128, 28, 28]             256\n",
      "        Hardswish-89           [1, 128, 28, 28]               0\n",
      "        ConvLayer-90           [1, 128, 28, 28]               0\n",
      "           Conv2d-91            [1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-92            [1, 64, 28, 28]             128\n",
      "        ConvLayer-93            [1, 64, 28, 28]               0\n",
      "           MBConv-94            [1, 64, 28, 28]               0\n",
      "    ResidualBlock-95            [1, 64, 28, 28]               0\n",
      "           Conv2d-96           [1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-97           [1, 256, 28, 28]             512\n",
      "        Hardswish-98           [1, 256, 28, 28]               0\n",
      "        ConvLayer-99           [1, 256, 28, 28]               0\n",
      "          Conv2d-100           [1, 256, 28, 28]           2,304\n",
      "     BatchNorm2d-101           [1, 256, 28, 28]             512\n",
      "       Hardswish-102           [1, 256, 28, 28]               0\n",
      "       ConvLayer-103           [1, 256, 28, 28]               0\n",
      "          Conv2d-104            [1, 64, 28, 28]          16,384\n",
      "     BatchNorm2d-105            [1, 64, 28, 28]             128\n",
      "       ConvLayer-106            [1, 64, 28, 28]               0\n",
      "          MBConv-107            [1, 64, 28, 28]               0\n",
      "   IdentityLayer-108            [1, 64, 28, 28]               0\n",
      "   ResidualBlock-109            [1, 64, 28, 28]               0\n",
      "          Conv2d-110           [1, 256, 28, 28]          16,384\n",
      "     BatchNorm2d-111           [1, 256, 28, 28]             512\n",
      "       Hardswish-112           [1, 256, 28, 28]               0\n",
      "       ConvLayer-113           [1, 256, 28, 28]               0\n",
      "          Conv2d-114           [1, 256, 28, 28]           2,304\n",
      "     BatchNorm2d-115           [1, 256, 28, 28]             512\n",
      "       Hardswish-116           [1, 256, 28, 28]               0\n",
      "       ConvLayer-117           [1, 256, 28, 28]               0\n",
      "          Conv2d-118            [1, 64, 28, 28]          16,384\n",
      "     BatchNorm2d-119            [1, 64, 28, 28]             128\n",
      "       ConvLayer-120            [1, 64, 28, 28]               0\n",
      "          MBConv-121            [1, 64, 28, 28]               0\n",
      "   IdentityLayer-122            [1, 64, 28, 28]               0\n",
      "   ResidualBlock-123            [1, 64, 28, 28]               0\n",
      "    OpSequential-124            [1, 64, 28, 28]               0\n",
      "    MBConv_stage-125            [1, 64, 28, 28]               0\n",
      "          Conv2d-126           [1, 256, 14, 14]         294,912\n",
      "     BatchNorm2d-127           [1, 256, 14, 14]             512\n",
      "            ReLU-128           [1, 256, 14, 14]               0\n",
      "          Conv2d-129           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-130           [1, 256, 14, 14]             512\n",
      "          Conv2d-131           [1, 256, 14, 14]          32,768\n",
      "     BatchNorm2d-132           [1, 256, 14, 14]             512\n",
      "            ReLU-133           [1, 256, 14, 14]               0\n",
      "      BasicBlock-134           [1, 256, 14, 14]               0\n",
      "          Conv2d-135           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-136           [1, 256, 14, 14]             512\n",
      "            ReLU-137           [1, 256, 14, 14]               0\n",
      "          Conv2d-138           [1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-139           [1, 256, 14, 14]             512\n",
      "            ReLU-140           [1, 256, 14, 14]               0\n",
      "      BasicBlock-141           [1, 256, 14, 14]               0\n",
      "    resnet_block-142           [1, 256, 14, 14]               0\n",
      "          Conv2d-143           [1, 256, 28, 28]          16,640\n",
      "       Hardswish-144           [1, 256, 28, 28]               0\n",
      "       ConvLayer-145           [1, 256, 28, 28]               0\n",
      "          Conv2d-146           [1, 256, 14, 14]           2,560\n",
      "       Hardswish-147           [1, 256, 14, 14]               0\n",
      "       ConvLayer-148           [1, 256, 14, 14]               0\n",
      "          Conv2d-149           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-150           [1, 128, 14, 14]             256\n",
      "       ConvLayer-151           [1, 128, 14, 14]               0\n",
      "          MBConv-152           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-153           [1, 128, 14, 14]               0\n",
      "          Conv2d-154           [1, 384, 14, 14]          49,152\n",
      "       ConvLayer-155           [1, 384, 14, 14]               0\n",
      "          Conv2d-156           [1, 384, 14, 14]           9,600\n",
      "          Conv2d-157           [1, 384, 14, 14]           6,144\n",
      "            ReLU-158           [1, 16, 16, 196]               0\n",
      "            ReLU-159           [1, 16, 16, 196]               0\n",
      "          Conv2d-160           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-161           [1, 128, 14, 14]             256\n",
      "       ConvLayer-162           [1, 128, 14, 14]               0\n",
      "         LiteMLA-163           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-164           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-165           [1, 128, 14, 14]               0\n",
      "          Conv2d-166           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-167           [1, 512, 14, 14]               0\n",
      "       ConvLayer-168           [1, 512, 14, 14]               0\n",
      "          Conv2d-169           [1, 512, 14, 14]           5,120\n",
      "       Hardswish-170           [1, 512, 14, 14]               0\n",
      "       ConvLayer-171           [1, 512, 14, 14]               0\n",
      "          Conv2d-172           [1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-173           [1, 128, 14, 14]             256\n",
      "       ConvLayer-174           [1, 128, 14, 14]               0\n",
      "          MBConv-175           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-176           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-177           [1, 128, 14, 14]               0\n",
      "EfficientViTBlock-178           [1, 128, 14, 14]               0\n",
      "          Conv2d-179           [1, 384, 14, 14]          49,152\n",
      "       ConvLayer-180           [1, 384, 14, 14]               0\n",
      "          Conv2d-181           [1, 384, 14, 14]           9,600\n",
      "          Conv2d-182           [1, 384, 14, 14]           6,144\n",
      "            ReLU-183           [1, 16, 16, 196]               0\n",
      "            ReLU-184           [1, 16, 16, 196]               0\n",
      "          Conv2d-185           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-186           [1, 128, 14, 14]             256\n",
      "       ConvLayer-187           [1, 128, 14, 14]               0\n",
      "         LiteMLA-188           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-189           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-190           [1, 128, 14, 14]               0\n",
      "          Conv2d-191           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-192           [1, 512, 14, 14]               0\n",
      "       ConvLayer-193           [1, 512, 14, 14]               0\n",
      "          Conv2d-194           [1, 512, 14, 14]           5,120\n",
      "       Hardswish-195           [1, 512, 14, 14]               0\n",
      "       ConvLayer-196           [1, 512, 14, 14]               0\n",
      "          Conv2d-197           [1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-198           [1, 128, 14, 14]             256\n",
      "       ConvLayer-199           [1, 128, 14, 14]               0\n",
      "          MBConv-200           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-201           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-202           [1, 128, 14, 14]               0\n",
      "EfficientViTBlock-203           [1, 128, 14, 14]               0\n",
      "          Conv2d-204           [1, 384, 14, 14]          49,152\n",
      "       ConvLayer-205           [1, 384, 14, 14]               0\n",
      "          Conv2d-206           [1, 384, 14, 14]           9,600\n",
      "          Conv2d-207           [1, 384, 14, 14]           6,144\n",
      "            ReLU-208           [1, 16, 16, 196]               0\n",
      "            ReLU-209           [1, 16, 16, 196]               0\n",
      "          Conv2d-210           [1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-211           [1, 128, 14, 14]             256\n",
      "       ConvLayer-212           [1, 128, 14, 14]               0\n",
      "         LiteMLA-213           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-214           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-215           [1, 128, 14, 14]               0\n",
      "          Conv2d-216           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-217           [1, 512, 14, 14]               0\n",
      "       ConvLayer-218           [1, 512, 14, 14]               0\n",
      "          Conv2d-219           [1, 512, 14, 14]           5,120\n",
      "       Hardswish-220           [1, 512, 14, 14]               0\n",
      "       ConvLayer-221           [1, 512, 14, 14]               0\n",
      "          Conv2d-222           [1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-223           [1, 128, 14, 14]             256\n",
      "       ConvLayer-224           [1, 128, 14, 14]               0\n",
      "          MBConv-225           [1, 128, 14, 14]               0\n",
      "   IdentityLayer-226           [1, 128, 14, 14]               0\n",
      "   ResidualBlock-227           [1, 128, 14, 14]               0\n",
      "EfficientViTBlock-228           [1, 128, 14, 14]               0\n",
      "    OpSequential-229           [1, 128, 14, 14]               0\n",
      "EfficientViT_stage-230           [1, 128, 14, 14]               0\n",
      "InterleavedLayer-231           [1, 384, 14, 14]               0\n",
      "          Conv2d-232           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-233           [1, 128, 14, 14]             256\n",
      "          Conv2d-234            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-235            [1, 16, 14, 14]              32\n",
      "          Conv2d-236           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-237           [1, 128, 14, 14]             256\n",
      "          Conv2d-238            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-239            [1, 16, 14, 14]              32\n",
      "          Conv2d-240           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-241           [1, 128, 14, 14]             256\n",
      "          Conv2d-242            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-243            [1, 16, 14, 14]              32\n",
      "          Conv2d-244           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-245           [1, 128, 14, 14]             256\n",
      "          Conv2d-246            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-247            [1, 16, 14, 14]              32\n",
      "            ReLU-248           [1, 384, 14, 14]               0\n",
      "          Conv2d-249           [1, 384, 14, 14]         147,456\n",
      "     BatchNorm2d-250           [1, 384, 14, 14]             768\n",
      "CascadedGroupAttention-251           [1, 384, 14, 14]               0\n",
      "          Conv2d-252           [1, 256, 14, 14]          98,560\n",
      "            ReLU-253           [1, 256, 14, 14]               0\n",
      "     BatchNorm2d-254           [1, 256, 14, 14]             512\n",
      "interaction_block-255           [1, 256, 14, 14]               0\n",
      "InterleavedLayer-256           [1, 384, 14, 14]               0\n",
      "          Conv2d-257           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-258           [1, 128, 14, 14]             256\n",
      "          Conv2d-259            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-260            [1, 16, 14, 14]              32\n",
      "          Conv2d-261           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-262           [1, 128, 14, 14]             256\n",
      "          Conv2d-263            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-264            [1, 16, 14, 14]              32\n",
      "          Conv2d-265           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-266           [1, 128, 14, 14]             256\n",
      "          Conv2d-267            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-268            [1, 16, 14, 14]              32\n",
      "          Conv2d-269           [1, 128, 14, 14]          12,288\n",
      "     BatchNorm2d-270           [1, 128, 14, 14]             256\n",
      "          Conv2d-271            [1, 16, 14, 14]             400\n",
      "     BatchNorm2d-272            [1, 16, 14, 14]              32\n",
      "            ReLU-273           [1, 384, 14, 14]               0\n",
      "          Conv2d-274           [1, 384, 14, 14]         147,456\n",
      "     BatchNorm2d-275           [1, 384, 14, 14]             768\n",
      "CascadedGroupAttention-276           [1, 384, 14, 14]               0\n",
      "          Conv2d-277           [1, 128, 14, 14]          49,280\n",
      "            ReLU-278           [1, 128, 14, 14]               0\n",
      "     BatchNorm2d-279           [1, 128, 14, 14]             256\n",
      "interaction_block-280           [1, 128, 14, 14]               0\n",
      "          Conv2d-281             [1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-282             [1, 512, 7, 7]           1,024\n",
      "            ReLU-283             [1, 512, 7, 7]               0\n",
      "          Conv2d-284             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-285             [1, 512, 7, 7]           1,024\n",
      "          Conv2d-286             [1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-287             [1, 512, 7, 7]           1,024\n",
      "            ReLU-288             [1, 512, 7, 7]               0\n",
      "      BasicBlock-289             [1, 512, 7, 7]               0\n",
      "          Conv2d-290             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-291             [1, 512, 7, 7]           1,024\n",
      "            ReLU-292             [1, 512, 7, 7]               0\n",
      "          Conv2d-293             [1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-294             [1, 512, 7, 7]           1,024\n",
      "            ReLU-295             [1, 512, 7, 7]               0\n",
      "      BasicBlock-296             [1, 512, 7, 7]               0\n",
      "    resnet_block-297             [1, 512, 7, 7]               0\n",
      "          Conv2d-298           [1, 512, 14, 14]          66,048\n",
      "       Hardswish-299           [1, 512, 14, 14]               0\n",
      "       ConvLayer-300           [1, 512, 14, 14]               0\n",
      "          Conv2d-301             [1, 512, 7, 7]           5,120\n",
      "       Hardswish-302             [1, 512, 7, 7]               0\n",
      "       ConvLayer-303             [1, 512, 7, 7]               0\n",
      "          Conv2d-304             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-305             [1, 256, 7, 7]             512\n",
      "       ConvLayer-306             [1, 256, 7, 7]               0\n",
      "          MBConv-307             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-308             [1, 256, 7, 7]               0\n",
      "          Conv2d-309             [1, 768, 7, 7]         196,608\n",
      "       ConvLayer-310             [1, 768, 7, 7]               0\n",
      "          Conv2d-311             [1, 768, 7, 7]          19,200\n",
      "          Conv2d-312             [1, 768, 7, 7]          12,288\n",
      "            ReLU-313            [1, 32, 16, 49]               0\n",
      "            ReLU-314            [1, 32, 16, 49]               0\n",
      "          Conv2d-315             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-316             [1, 256, 7, 7]             512\n",
      "       ConvLayer-317             [1, 256, 7, 7]               0\n",
      "         LiteMLA-318             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-319             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-320             [1, 256, 7, 7]               0\n",
      "          Conv2d-321            [1, 1024, 7, 7]         263,168\n",
      "       Hardswish-322            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-323            [1, 1024, 7, 7]               0\n",
      "          Conv2d-324            [1, 1024, 7, 7]          10,240\n",
      "       Hardswish-325            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-326            [1, 1024, 7, 7]               0\n",
      "          Conv2d-327             [1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-328             [1, 256, 7, 7]             512\n",
      "       ConvLayer-329             [1, 256, 7, 7]               0\n",
      "          MBConv-330             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-331             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-332             [1, 256, 7, 7]               0\n",
      "EfficientViTBlock-333             [1, 256, 7, 7]               0\n",
      "          Conv2d-334             [1, 768, 7, 7]         196,608\n",
      "       ConvLayer-335             [1, 768, 7, 7]               0\n",
      "          Conv2d-336             [1, 768, 7, 7]          19,200\n",
      "          Conv2d-337             [1, 768, 7, 7]          12,288\n",
      "            ReLU-338            [1, 32, 16, 49]               0\n",
      "            ReLU-339            [1, 32, 16, 49]               0\n",
      "          Conv2d-340             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-341             [1, 256, 7, 7]             512\n",
      "       ConvLayer-342             [1, 256, 7, 7]               0\n",
      "         LiteMLA-343             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-344             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-345             [1, 256, 7, 7]               0\n",
      "          Conv2d-346            [1, 1024, 7, 7]         263,168\n",
      "       Hardswish-347            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-348            [1, 1024, 7, 7]               0\n",
      "          Conv2d-349            [1, 1024, 7, 7]          10,240\n",
      "       Hardswish-350            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-351            [1, 1024, 7, 7]               0\n",
      "          Conv2d-352             [1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-353             [1, 256, 7, 7]             512\n",
      "       ConvLayer-354             [1, 256, 7, 7]               0\n",
      "          MBConv-355             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-356             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-357             [1, 256, 7, 7]               0\n",
      "EfficientViTBlock-358             [1, 256, 7, 7]               0\n",
      "          Conv2d-359             [1, 768, 7, 7]         196,608\n",
      "       ConvLayer-360             [1, 768, 7, 7]               0\n",
      "          Conv2d-361             [1, 768, 7, 7]          19,200\n",
      "          Conv2d-362             [1, 768, 7, 7]          12,288\n",
      "            ReLU-363            [1, 32, 16, 49]               0\n",
      "            ReLU-364            [1, 32, 16, 49]               0\n",
      "          Conv2d-365             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-366             [1, 256, 7, 7]             512\n",
      "       ConvLayer-367             [1, 256, 7, 7]               0\n",
      "         LiteMLA-368             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-369             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-370             [1, 256, 7, 7]               0\n",
      "          Conv2d-371            [1, 1024, 7, 7]         263,168\n",
      "       Hardswish-372            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-373            [1, 1024, 7, 7]               0\n",
      "          Conv2d-374            [1, 1024, 7, 7]          10,240\n",
      "       Hardswish-375            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-376            [1, 1024, 7, 7]               0\n",
      "          Conv2d-377             [1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-378             [1, 256, 7, 7]             512\n",
      "       ConvLayer-379             [1, 256, 7, 7]               0\n",
      "          MBConv-380             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-381             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-382             [1, 256, 7, 7]               0\n",
      "EfficientViTBlock-383             [1, 256, 7, 7]               0\n",
      "          Conv2d-384             [1, 768, 7, 7]         196,608\n",
      "       ConvLayer-385             [1, 768, 7, 7]               0\n",
      "          Conv2d-386             [1, 768, 7, 7]          19,200\n",
      "          Conv2d-387             [1, 768, 7, 7]          12,288\n",
      "            ReLU-388            [1, 32, 16, 49]               0\n",
      "            ReLU-389            [1, 32, 16, 49]               0\n",
      "          Conv2d-390             [1, 256, 7, 7]         131,072\n",
      "     BatchNorm2d-391             [1, 256, 7, 7]             512\n",
      "       ConvLayer-392             [1, 256, 7, 7]               0\n",
      "         LiteMLA-393             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-394             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-395             [1, 256, 7, 7]               0\n",
      "          Conv2d-396            [1, 1024, 7, 7]         263,168\n",
      "       Hardswish-397            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-398            [1, 1024, 7, 7]               0\n",
      "          Conv2d-399            [1, 1024, 7, 7]          10,240\n",
      "       Hardswish-400            [1, 1024, 7, 7]               0\n",
      "       ConvLayer-401            [1, 1024, 7, 7]               0\n",
      "          Conv2d-402             [1, 256, 7, 7]         262,144\n",
      "     BatchNorm2d-403             [1, 256, 7, 7]             512\n",
      "       ConvLayer-404             [1, 256, 7, 7]               0\n",
      "          MBConv-405             [1, 256, 7, 7]               0\n",
      "   IdentityLayer-406             [1, 256, 7, 7]               0\n",
      "   ResidualBlock-407             [1, 256, 7, 7]               0\n",
      "EfficientViTBlock-408             [1, 256, 7, 7]               0\n",
      "    OpSequential-409             [1, 256, 7, 7]               0\n",
      "EfficientViT_stage-410             [1, 256, 7, 7]               0\n",
      "     ConcatLayer-411             [1, 768, 7, 7]               0\n",
      "          Conv2d-412             [1, 768, 7, 7]           1,536\n",
      "          Conv2d-413             [1, 768, 7, 7]         590,592\n",
      "       LayerNorm-414             [1, 768, 7, 7]          75,264\n",
      "    concat_block-415             [1, 768, 7, 7]               0\n",
      "restevit_road_backbone-416             [1, 768, 7, 7]               0\n",
      "AdaptiveAvgPool2d-417             [1, 768, 1, 1]               0\n",
      "         Flatten-418                   [1, 768]               0\n",
      "         Dropout-419                   [1, 768]               0\n",
      "            ReLU-420                   [1, 768]               0\n",
      "          Linear-421                     [1, 2]           1,538\n",
      "================================================================\n",
      "Total params: 17,038,242\n",
      "Trainable params: 17,038,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 278.42\n",
      "Params size (MB): 65.00\n",
      "Estimated Total Size (MB): 343.99\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add_ encountered 82 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::hardswish encountered 30 time(s)\n",
      "Unsupported operator aten::add encountered 41 time(s)\n",
      "Unsupported operator aten::mul encountered 15 time(s)\n",
      "Unsupported operator aten::pad encountered 7 time(s)\n",
      "Unsupported operator aten::div encountered 7 time(s)\n",
      "Unsupported operator aten::softmax encountered 8 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_mdoel.efficientvit_in.input_stem.op_list.1.shortcut, base_mdoel.stage1.stage.op_list.1.shortcut, base_mdoel.stage2.stage.op_list.1.shortcut, base_mdoel.stage2.stage.op_list.2.shortcut, base_mdoel.stage3.stage.op_list.1.context_module.shortcut, base_mdoel.stage3.stage.op_list.1.local_module.shortcut, base_mdoel.stage3.stage.op_list.2.context_module.shortcut, base_mdoel.stage3.stage.op_list.2.local_module.shortcut, base_mdoel.stage3.stage.op_list.3.context_module.shortcut, base_mdoel.stage3.stage.op_list.3.local_module.shortcut, base_mdoel.stage4.stage.op_list.1.context_module.shortcut, base_mdoel.stage4.stage.op_list.1.local_module.shortcut, base_mdoel.stage4.stage.op_list.2.context_module.shortcut, base_mdoel.stage4.stage.op_list.2.local_module.shortcut, base_mdoel.stage4.stage.op_list.3.context_module.shortcut, base_mdoel.stage4.stage.op_list.3.local_module.shortcut, base_mdoel.stage4.stage.op_list.4.context_module.shortcut, base_mdoel.stage4.stage.op_list.4.local_module.shortcut\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'| module                                                  | #parameters or shape   | #flops     |\\n|:--------------------------------------------------------|:-----------------------|:-----------|\\n| model                                                   | 17.04M                 | 2.516G     |\\n|  base_mdoel                                             |  17.038M               |  2.516G    |\\n|   base_mdoel.resnet_in                                  |   9.536K               |   0.122G   |\\n|    base_mdoel.resnet_in.conv                            |    9.408K              |    0.118G  |\\n|    base_mdoel.resnet_in.bn                              |    0.128K              |    4.014M  |\\n|   base_mdoel.efficientvit_in.input_stem.op_list         |   0.928K               |   13.447M  |\\n|    base_mdoel.efficientvit_in.input_stem.op_list.0      |    0.464K              |    6.423M  |\\n|    base_mdoel.efficientvit_in.input_stem.op_list.1.main |    0.464K              |    7.025M  |\\n|   base_mdoel.block1.blocks                              |   0.148M               |   0.466G   |\\n|    base_mdoel.block1.blocks.0                           |    73.984K             |    0.233G  |\\n|    base_mdoel.block1.blocks.1                           |    73.984K             |    0.233G  |\\n|   base_mdoel.block2.blocks                              |   0.526M               |   0.414G   |\\n|    base_mdoel.block2.blocks.0                           |    0.23M               |    0.181G  |\\n|    base_mdoel.block2.blocks.1                           |    0.295M              |    0.232G  |\\n|   base_mdoel.block3.blocks                              |   2.1M                 |   0.412G   |\\n|    base_mdoel.block3.blocks.0                           |    0.919M              |    0.181G  |\\n|    base_mdoel.block3.blocks.1                           |    1.181M              |    0.232G  |\\n|   base_mdoel.block4.blocks                              |   8.394M               |   0.412G   |\\n|    base_mdoel.block4.blocks.0                           |    3.673M              |    0.18G   |\\n|    base_mdoel.block4.blocks.1                           |    4.721M              |    0.231G  |\\n|   base_mdoel.stage1.stage.op_list                       |   13.888K              |   60.412M  |\\n|    base_mdoel.stage1.stage.op_list.0.main               |    3.968K              |    26.593M |\\n|    base_mdoel.stage1.stage.op_list.1.main               |    9.92K               |    33.819M |\\n|   base_mdoel.stage2.stage.op_list                       |   86.528K              |   82.439M  |\\n|    base_mdoel.stage2.stage.op_list.0.main               |    14.08K              |    22.93M  |\\n|    base_mdoel.stage2.stage.op_list.1.main               |    36.224K             |    29.754M |\\n|    base_mdoel.stage2.stage.op_list.2.main               |    36.224K             |    29.754M |\\n|   base_mdoel.stage3.stage.op_list                       |   0.757M               |   0.163G   |\\n|    base_mdoel.stage3.stage.op_list.0.main               |    52.224K             |    19.845M |\\n|    base_mdoel.stage3.stage.op_list.1                    |    0.235M              |    47.692M |\\n|    base_mdoel.stage3.stage.op_list.2                    |    0.235M              |    47.692M |\\n|    base_mdoel.stage3.stage.op_list.3                    |    0.235M              |    47.692M |\\n|   base_mdoel.stage4.stage.op_list                       |   3.786M               |   0.198G   |\\n|    base_mdoel.stage4.stage.op_list.0.main               |    0.203M              |    19.556M |\\n|    base_mdoel.stage4.stage.op_list.1                    |    0.896M              |    44.719M |\\n|    base_mdoel.stage4.stage.op_list.2                    |    0.896M              |    44.719M |\\n|    base_mdoel.stage4.stage.op_list.3                    |    0.896M              |    44.719M |\\n|    base_mdoel.stage4.stage.op_list.4                    |    0.896M              |    44.719M |\\n|   base_mdoel.concat_block                               |   0.667M               |   29.127M  |\\n|    base_mdoel.concat_block.dw_conv                      |    1.536K              |    37.632K |\\n|    base_mdoel.concat_block.point_conv                   |    0.591M              |    28.901M |\\n|    base_mdoel.concat_block.nor                          |    75.264K             |    0.188M  |\\n|   base_mdoel.interaction_to_r                           |   0.3M                 |   76.518M  |\\n|    base_mdoel.interaction_to_r.attn                     |    0.201M              |    57M     |\\n|    base_mdoel.interaction_to_r.downchannel              |    98.56K              |    19.268M |\\n|    base_mdoel.interaction_to_r.bn                       |    0.512K              |    0.251M  |\\n|   base_mdoel.interaction_to_v                           |   0.25M                |   66.759M  |\\n|    base_mdoel.interaction_to_v.attn                     |    0.201M              |    57M     |\\n|    base_mdoel.interaction_to_v.downchannel              |    49.28K              |    9.634M  |\\n|    base_mdoel.interaction_to_v.bn                       |    0.256K              |    0.125M  |\\n|  classification.3                                       |  1.538K                |  1.536K    |\\n|   classification.3.weight                               |   (2, 768)             |            |\\n|   classification.3.bias                                 |   (2,)                 |            |\\n|  apdative                                               |                        |  37.632K   |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=restevit_road_cls()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model= model.to(device)\n",
    "summary(model, (3,224,224), batch_size=1)\n",
    "inputs= torch.rand(1,3, 224,224)\n",
    "inputs=inputs.to(device)\n",
    "flops=FlopCountAnalysis(model,inputs)\n",
    "flops.total()\n",
    "flop_count_table(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbe0195-54e6-44f2-a70d-eefc0a68a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "def train(epochs_per_fold=25,batch_size=32,image_size=224):\n",
    "    checkpoint = torch.load('ResEViT_model.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    for fold,(dataloader_dict) in enumerate(Torch_load(image_size=image_size,batch_size=batch_size)()):\n",
    "        print(\"Fold:\",fold+1)\n",
    "        criterior= nn.CrossEntropyLoss()\n",
    "        if fold<1: optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "        elif fold<3: optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "        else: optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "        early_stop_thresh = 5\n",
    "        best_accuracy = -1\n",
    "        best_epoch = -1\n",
    "        stop=False\n",
    "        for epoch in range(epochs_per_fold):\n",
    "            if stop==True: break\n",
    "            with open('output2.txt', 'a') as f:\n",
    "                print(\"Epoch {}/{}\".format(epoch, epochs_per_fold),file=f)\n",
    "            for phase in [\"Train\", \"Val\"]:\n",
    "                if phase == \"Train\":\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    \n",
    "                epoch_loss = 0.0\n",
    "                epoch_corrects = 0\n",
    "                \n",
    "                for inputs, labels in tqdm(dataloader_dict[phase]):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == \"Train\"):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterior(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        \n",
    "                        if phase == \"Train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                    epoch_loss += loss.item()*inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds==labels.data)\n",
    "                epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "                epoch_accuracy = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "                if phase == \"Val\":\n",
    "                    if epoch_accuracy > best_accuracy:\n",
    "                        best_accuracy = epoch_accuracy\n",
    "                        best_epoch = epoch\n",
    "                        save_checkpoint(model, \"ResEViT_model.pth\")\n",
    "                    elif epoch - best_epoch > early_stop_thresh:\n",
    "                        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "                        stop=True  # terminate the training loop\n",
    "                        \n",
    "                with open('output2.txt', 'a') as f:\n",
    "                    print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_accuracy), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016506bb-7542-4d7e-b51f-1971db7bf16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 558/558 [04:13<00:00,  2.20it/s]\n",
      "100%|██████████| 140/140 [00:48<00:00,  2.89it/s]\n",
      "100%|██████████| 558/558 [04:05<00:00,  2.28it/s]\n",
      "100%|██████████| 140/140 [00:47<00:00,  2.93it/s]\n",
      "100%|██████████| 558/558 [04:08<00:00,  2.25it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.84it/s]\n",
      "100%|██████████| 558/558 [04:29<00:00,  2.07it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.77it/s]\n",
      "100%|██████████| 558/558 [04:25<00:00,  2.10it/s]\n",
      "100%|██████████| 140/140 [00:48<00:00,  2.90it/s]\n",
      "100%|██████████| 558/558 [04:35<00:00,  2.03it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.78it/s]\n",
      "100%|██████████| 558/558 [04:10<00:00,  2.23it/s]\n",
      "100%|██████████| 140/140 [00:48<00:00,  2.88it/s]\n",
      "100%|██████████| 558/558 [04:30<00:00,  2.07it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.78it/s]\n",
      "100%|██████████| 558/558 [04:20<00:00,  2.14it/s]\n",
      "100%|██████████| 140/140 [00:48<00:00,  2.86it/s]\n",
      "100%|██████████| 558/558 [04:29<00:00,  2.07it/s]\n",
      "100%|██████████| 140/140 [00:48<00:00,  2.90it/s]\n",
      "100%|██████████| 558/558 [04:14<00:00,  2.19it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.82it/s]\n",
      "100%|██████████| 558/558 [04:28<00:00,  2.08it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.77it/s]\n",
      "100%|██████████| 558/558 [04:29<00:00,  2.07it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.85it/s]\n",
      "100%|██████████| 558/558 [04:29<00:00,  2.07it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.80it/s]\n",
      "100%|██████████| 558/558 [04:39<00:00,  2.00it/s]\n",
      "100%|██████████| 140/140 [00:48<00:00,  2.90it/s]\n",
      "100%|██████████| 558/558 [04:38<00:00,  2.00it/s]\n",
      "100%|██████████| 140/140 [00:51<00:00,  2.70it/s]\n",
      "100%|██████████| 558/558 [04:30<00:00,  2.07it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.85it/s]\n",
      "100%|██████████| 558/558 [04:33<00:00,  2.04it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.79it/s]\n",
      "100%|██████████| 558/558 [04:33<00:00,  2.04it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.85it/s]\n",
      "100%|██████████| 558/558 [04:33<00:00,  2.04it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.75it/s]\n",
      "100%|██████████| 558/558 [04:37<00:00,  2.01it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.82it/s]\n",
      "100%|██████████| 558/558 [04:33<00:00,  2.04it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.75it/s]\n",
      "100%|██████████| 558/558 [04:34<00:00,  2.03it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.82it/s]\n",
      "100%|██████████| 558/558 [04:16<00:00,  2.18it/s]\n",
      "100%|██████████| 140/140 [00:51<00:00,  2.73it/s]\n",
      "100%|██████████| 558/558 [04:17<00:00,  2.17it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 558/558 [04:11<00:00,  2.22it/s]\n",
      "100%|██████████| 140/140 [00:49<00:00,  2.81it/s]\n",
      "100%|██████████| 558/558 [04:05<00:00,  2.27it/s]\n",
      "100%|██████████| 140/140 [00:50<00:00,  2.78it/s]\n",
      " 65%|██████▍   | 361/558 [02:40<01:27,  2.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs_per_fold, batch_size, image_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     28\u001b[0m epoch_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader_dict[phase]):\n\u001b[1;32m     31\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Train_standard/Load_data/Torch_load.py:78\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     76\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list[idx]\n\u001b[1;32m     77\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\n\u001b[0;32m---> 78\u001b[0m img_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m parent_dir \u001b[38;5;241m=\u001b[39m parent_dir \u001b[38;5;241m=\u001b[39m img_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent_dir\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBadRoad\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Train_standard/Load_data/Torch_load.py:38\u001b[0m, in \u001b[0;36mImageTransform.__call__\u001b[0;34m(self, img, phase)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_transform\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/torchvision/transforms/transforms.py:479\u001b[0m, in \u001b[0;36mLambda.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlambd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Train_standard/Load_data/Torch_load.py:11\u001b[0m, in \u001b[0;36mtop_crop\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtop_crop\u001b[39m(img):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/PIL/Image.py:1219\u001b[0m, in \u001b[0;36mImage.crop\u001b[0;34m(self, box)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinate \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is less than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1219\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim, box))\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7520d53-ce1b-4d9a-9d8c-4b2962ee523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:24<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8571    0.8854    0.8710       942\n",
      "         1.0     0.8552    0.8211    0.8378       777\n",
      "\n",
      "    accuracy                         0.8563      1719\n",
      "   macro avg     0.8562    0.8532    0.8544      1719\n",
      "weighted avg     0.8563    0.8563    0.8560      1719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('ResEViT_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "# torch.save(model, './ResEViT_model')\n",
    "# model = torch.load('./ResEViT_model')\n",
    "Test_data=load_test(16,224)\n",
    "Class_Report(Test_data,model,device)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5be13-e96b-4e9f-8706-bbea4d50c0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
